<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face & Gaze Detection System</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background-color: #1a1a1a;
            color: #ffffff;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: flex-start;
            height: 100vh;
            margin: 0;
            padding: 20px;
            box-sizing: border-box;
        }

        h1 {
            border-bottom: 2px solid #00ffcc;
            padding-bottom: 5px;
            margin-bottom: 10px;
            margin-top: 0;
            font-size: 1.5rem;
        }

        /* Large Warning Display */
        #warningDisplay {
            width: 80%;
            text-align: center;
            font-size: 1.5rem;
            font-weight: bold;
            padding: 10px;
            margin-bottom: 15px;
            border-radius: 8px;
            background-color: #333;
            color: #00ffcc;
            min-height: 40px;
            transition: background-color 0.3s, color 0.3s;
        }

        #warningDisplay.alert {
            background-color: #ff4444;
            color: white;
            animation: pulse 1s infinite;
        }

        @keyframes pulse {
            0% {
                transform: scale(1);
            }

            50% {
                transform: scale(1.02);
            }

            100% {
                transform: scale(1);
            }
        }

        .video-container {
            border: 3px solid #333;
            border-radius: 8px;
            box-shadow: 0 0 15px rgba(0, 0, 0, 0.5);
            overflow: hidden;
            width: 100%;
            max-width: 800px;
            /* 1280x720 aspect ratio */
            aspect-ratio: 16/9;
            flex-grow: 1;
            display: flex;
            align-items: center;
            justify-content: center;
            background: #000;
            position: relative;
        }

        /* Access to local webcam video (hidden, we draw to canvas) */
        #localVideo {
            display: none;
        }

        /* Main Display Canvas */
        #videoCanvas {
            width: 100%;
            height: 100%;
            object-fit: contain;
        }

        .controls {
            margin-top: 15px;
            display: flex;
            gap: 15px;
            align-items: center;
            justify-content: center;
            background: #2a2a2a;
            padding: 10px 20px;
            border-radius: 50px;
        }

        button {
            padding: 8px 16px;
            cursor: pointer;
            border: none;
            border-radius: 4px;
            font-weight: bold;
            background-color: #00ffcc;
            color: #000;
            transition: opacity 0.2s;
        }

        button:hover {
            opacity: 0.8;
        }

        .stop-btn {
            background-color: #ff4444;
            color: white;
        }

        /* Status Overlay on Canvas (optional, if we want raw text) */
        #statsOverlay {
            position: absolute;
            top: 10px;
            left: 10px;
            color: #0f0;
            font-family: monospace;
            background: rgba(0, 0, 0, 0.5);
            padding: 5px;
            pointer-events: none;
        }
    </style>
</head>

<body>
    <h1>Face & Gaze Security Monitor (Client-Side)</h1>

    <div id="warningDisplay">System Safe</div>

    <div class="video-container">
        <!-- Hidden source video -->
        <video id="localVideo" autoplay muted playsinline></video>
        <!-- Drawing Canvas -->
        <canvas id="videoCanvas"></canvas>

        <button onclick="toggleFullScreen()"
            style="position: absolute; top: 10px; right: 10px; background: rgba(0,0,0,0.5); color: white; border: 1px solid white;">
            ⤢ Fullscreen
        </button>
    </div>

    <div class="controls">
        <button onclick="stopServer()" class="stop-btn">Stop Server</button>
        <span id="fpsDisplay" style="margin-left: 20px; font-weight: bold; color: #00ffcc;">FPS: 0</span>
    </div>

    <!-- Interview Overlay/Panel -->
    <div id="interviewPanel"
        style="background: #2a2a2a; padding: 20px; border-radius: 12px; margin-top: 20px; width: 80%; text-align: center;">
        <div id="initialView">
            <h2>Ready to Start?</h2>
            <input type="text" id="candidateName" placeholder="Enter Your Name"
                style="padding: 10px; border-radius: 4px; border: none; margin-bottom: 10px; width: 60%;">
            <br>
            <button onclick="startInterview()">Start Interview</button>
        </div>

        <div id="questionView" style="display:none;">
            <div id="questionText"
                style="font-size: 1.2rem; margin-bottom: 20px; min-height: 3em; font-weight: bold; color: #00ffcc;">
                Waiting for question...
            </div>
            <div class="interview-controls">
                <button id="submitAudioBtn" onclick="stopRecordingAndSubmit()" disabled
                    style="background-color: #555; cursor: not-allowed;">Submit Audio</button>
                <div id="recordingStatus" style="margin-top: 10px; font-size: 0.9em; color: #aaa;"></div>
            </div>
            <audio id="ttsPlayer" style="display:none;"></audio>
        </div>

        <div id="finishedView" style="display:none;">
            <h2 style="color: #00ffcc;">Questions Completed</h2>
            <p>Please click below to submit your interview for analysis.</p>
            <button onclick="finalizeInterview()" style="font-size: 1.2rem; padding: 15px 30px;">Finish
                Interview</button>
        </div>

        <div id="finalThankYou" style="display:none;">
            <h2 style="color: #00ffcc;">Interview Submitted</h2>
            <p>You may now close this window.</p>
        </div>
    </div>

    <script>
        // --- 1. Client-Side Video Logic ---
        const localVideo = document.getElementById('localVideo');
        const canvas = document.getElementById('videoCanvas');
        const ctx = canvas.getContext('2d');
        const warningDisplay = document.getElementById('warningDisplay');

        let videoWs = null;
        let lastAnalysis = null;
        let frameCount = 0;
        let lastFPSUpdate = performance.now();

        // Start Camera
        async function startCamera() {
            console.log("Initializing Camera...");
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: { width: 640, height: 480, frameRate: 15 },
                    audio: false
                });
                console.log("Camera Stream obtained:", stream.id);
                localVideo.srcObject = stream;

                localVideo.onloadeddata = () => {
                    console.log("Video data loaded. Dimensions:", localVideo.videoWidth, "x", localVideo.videoHeight);
                    canvas.width = localVideo.videoWidth;
                    canvas.height = localVideo.videoHeight;
                    localVideo.play().then(() => {
                        console.log("Local video playback started.");
                        requestAnimationFrame(drawLoop);
                        connectVideoWebSocket();
                    }).catch(err => {
                        console.error("Playback failed:", err);
                    });
                };

                localVideo.onerror = (err) => {
                    console.error("Local Video Error:", err);
                };

            } catch (err) {
                console.error("Camera Access Error:", err);
                alert("Camera Access Denied or Not Found! " + err.message);
            }
        }

        // WebSocket for Video Streaming
        function connectVideoWebSocket() {
            const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsUrl = `${protocol}//${window.location.host}/ws/video`;
            console.log("Connecting to Video WebSocket:", wsUrl);
            videoWs = new WebSocket(wsUrl);

            videoWs.onopen = () => console.log("Video Stream WS Connected");
            videoWs.onmessage = (event) => {
                try {
                    lastAnalysis = JSON.parse(event.data);
                    updateWarning(lastAnalysis.warning);
                } catch (e) {
                    console.error("WS Message Error:", e);
                }
            };
            videoWs.onclose = (e) => {
                console.log("Video WS Closed. Reason:", e.reason, "Code:", e.code);
                setTimeout(connectVideoWebSocket, 2000);
            };
            videoWs.onerror = (err) => {
                console.error("Video WS Error:", err);
            };
        }

        function updateWarning(msg) {
            if (msg) {
                warningDisplay.innerText = msg;
                warningDisplay.classList.add('alert');
            } else {
                warningDisplay.innerText = "System Safe";
                warningDisplay.classList.remove('alert');
            }
        }

        let lastSendTime = 0;
        const SEND_INTERVAL = 100; // Send 10 FPS to server (100ms)

        function drawLoop(timestamp) {
            if (!localVideo.paused && !localVideo.ended) {
                // Draw video to canvas
                ctx.drawImage(localVideo, 0, 0, canvas.width, canvas.height);

                // Send Frame to Server (Throttled)
                if (videoWs && videoWs.readyState === WebSocket.OPEN && (timestamp - lastSendTime > SEND_INTERVAL)) {
                    canvas.toBlob(blob => {
                        if (blob) {
                            videoWs.send(blob);
                        }
                    }, 'image/jpeg', 0.5);
                    lastSendTime = timestamp;
                }

                // Draw Overlays from latest server analysis
                if (lastAnalysis) {
                    drawOverlays(lastAnalysis);
                }
            } else {
                // console.warn("Video playback paused or ended.");
            }

            // FPS Counter
            frameCount++;
            if (timestamp - lastFPSUpdate >= 1000) {
                document.getElementById('fpsDisplay').innerText = `FPS: ${frameCount}`;
                frameCount = 0;
                lastFPSUpdate = timestamp;
            }

            requestAnimationFrame(drawLoop);
        }

        function drawOverlays(data) {
            const { box, auth, gaze } = data;

            // Text Color
            const color = auth ? '#00ff00' : '#ff0000';
            ctx.strokeStyle = color;
            ctx.lineWidth = 3;
            ctx.fillStyle = color;
            ctx.font = "20px Arial";

            // Draw Face Box
            if (box) {
                const [top, right, bottom, left] = box;
                ctx.strokeRect(left, top, right - left, bottom - top);
                ctx.fillText(`Auth: ${auth}`, left, top - 10);
            }

            // Draw Gaze Text
            ctx.fillStyle = data.warning ? 'red' : 'yellow';
            ctx.fillText(`Gaze: ${gaze}`, 20, 50);
        }

        function toggleFullScreen() {
            if (!document.fullscreenElement) {
                document.documentElement.requestFullscreen();
            } else {
                if (document.exitFullscreen) {
                    document.exitFullscreen();
                }
            }
        }

        // Start everything on load
        window.addEventListener('load', startCamera);


        // --- 2. Existing Audio/Interview Logic (Untouched) ---
        // (Copied from previous logic, ensuring it works with `startCamera` handling video)

        function playStartSound() {
            try {
                const ctx = new (window.AudioContext || window.webkitAudioContext)();
                const osc = ctx.createOscillator();
                const gain = ctx.createGain();
                osc.connect(gain);
                gain.connect(ctx.destination);
                osc.type = "sine";
                osc.frequency.setValueAtTime(880, ctx.currentTime);
                osc.frequency.exponentialRampToValueAtTime(440, ctx.currentTime + 0.1);
                gain.gain.setValueAtTime(0.05, ctx.currentTime);
                gain.gain.exponentialRampToValueAtTime(0.001, ctx.currentTime + 0.3);
                osc.start();
                osc.stop(ctx.currentTime + 0.3);
            } catch (e) { }
        }

        let currentSessionId = null;
        let currentQuestionId = null;
        let mediaRecorder = null;
        let audioChunks = [];

        async function startInterview() {
            const name = document.getElementById('candidateName').value || "Candidate";
            const initialView = document.getElementById('initialView');

            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                const enrollmentRecorder = new MediaRecorder(stream);
                const chunks = [];

                enrollmentRecorder.ondataavailable = e => chunks.push(e.data);
                enrollmentRecorder.onstop = async () => {
                    const blob = new Blob(chunks, { type: 'audio/wav' });
                    const formData = new FormData();
                    formData.append('candidate_name', name);
                    formData.append('enrollment_audio', blob);

                    const res = await fetch('/interview/start', { method: 'POST', body: formData });
                    const data = await res.json();

                    if (data.warning) {
                        alert("⚠️ Warning: " + data.warning);
                    }

                    currentSessionId = data.session_id;

                    initialView.style.display = 'none';
                    document.getElementById('questionView').style.display = 'block';
                    fetchNextQuestion();
                };

                enrollmentRecorder.start();
                playStartSound();
                initialView.innerHTML = "<h2>Enrolling Voice Fingerprint...</h2><p>Please say 'I am ready for the interview'</p>";

                setTimeout(() => {
                    enrollmentRecorder.stop();
                    // Don't stop tracks here, we might lose microphone permission? 
                    // Actually, safer to keep validation stream separate.
                    stream.getTracks().forEach(track => track.stop());
                }, 5000);

            } catch (err) {
                alert("Microphone required for interview security.");
            }
        }

        async function fetchNextQuestion() {
            const status = document.getElementById('recordingStatus');
            const submitBtn = document.getElementById('submitAudioBtn');
            const questionText = document.getElementById('questionText');

            status.innerText = "Loading question...";
            submitBtn.disabled = true;
            submitBtn.style.backgroundColor = "#555";
            submitBtn.style.cursor = "not-allowed";

            const res = await fetch(`/interview/next-question/${currentSessionId}`);
            const data = await res.json();

            if (data.status === 'finished') {
                document.getElementById('questionView').style.display = 'none';
                document.getElementById('finishedView').style.display = 'block';
                return;
            }

            currentQuestionId = data.question_id;
            questionText.innerText = data.text;

            const player = document.getElementById('ttsPlayer');
            player.src = data.audio_url;
            player.play();

            player.onended = () => {
                status.innerText = "Computer ended speaking. Waiting 2 seconds...";
                setTimeout(() => {
                    startRecording();
                }, 2000);
            };
        }

        async function startRecording() {
            const status = document.getElementById('recordingStatus');
            const submitBtn = document.getElementById('submitAudioBtn');

            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];

                mediaRecorder.ondataavailable = (event) => audioChunks.push(event.data);
                mediaRecorder.onstop = async () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                    await submitAudio(audioBlob);
                };

                mediaRecorder.start();
                playStartSound();
                status.innerText = "Listening... Speak your answer.";
                submitBtn.disabled = false;
                submitBtn.style.backgroundColor = "#00ffcc";
                submitBtn.style.color = "#000";
                submitBtn.style.cursor = "pointer";
            } catch (err) {
                console.error("Microphone error:", err);
                status.innerText = "Error accessing microphone.";
            }
        }

        function stopRecordingAndSubmit() {
            if (mediaRecorder && mediaRecorder.state === "recording") {
                mediaRecorder.stop();
                document.getElementById('recordingStatus').innerText = "Submitting...";
                document.getElementById('submitAudioBtn').disabled = true;
            }
        }

        async function submitAudio(blob) {
            const formData = new FormData();
            formData.append('session_id', currentSessionId);
            formData.append('question_id', currentQuestionId);
            formData.append('audio', blob, 'answer.wav');

            const res = await fetch('/interview/submit-answer', { method: 'POST', body: formData });
            if (res.ok) fetchNextQuestion();
            else alert("Error submitting audio");
        }

        async function finalizeInterview() {
            await fetch(`/interview/finish/${currentSessionId}`, { method: 'POST' });
            document.getElementById('finishedView').style.display = 'none';
            document.getElementById('finalThankYou').style.display = 'block';
        }

        async function stopServer() {
            if (!confirm("Are you sure you want to stop the server?")) return;
            try {
                await fetch('/shutdown', { method: 'POST' });
                alert("Server Service Stopped.");
                document.body.innerHTML = "<h1 style='color:white;text-align:center;margin-top:20%'>Server Stopped</h1>";
            } catch (e) { }
        }
    </script>
</body>

</html>